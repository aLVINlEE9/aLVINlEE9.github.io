---
layout: post
title: 강화학습이란?
comments: true
categories: [DataScience/Reinforcement Learning]
tags: [Reinforcement Learning, 강화학습, rl]
date: 2021-10-14 22:00:00
---

<br/>

# 강화학습이란?

​	강화라는 개념을 처음 제시한 학자인 스키너의 실험(행동심리학)을 이해하면 강화학습이 무엇인지 알 수 있다.

​	![img](http://image.yes24.com/blogimage/blog/h/w/hws321/9iaoJ0BP.jpg)

```
1. 굶긴 쥐를 상자에 넣는다.
2. 쥐는 돌아다니다가 우연히 상자 안에 있는 지렛대를 누르게 된다.
3. 지렛대를 누르자 먹이가 나온다.
4. 지렛대를 누르는 행동과 먹이와의 상관관계를 모르는 쥐는 다시 돌아다닌다.
5. 그러다가 우연히 쥐가 다시 지렛대를 누르면 쥐는 이제 먹이와 지렛대 사이의 관계를 알게 되고 점점 지렛대를 자주 누르게 된다.(강화)
6. 이 과정을 반복하면서 쥐는 지렛대를 누르면 먹이(보상)를 먹을 수 있다는 것을 학습한다.
```

​	위 과정을 통해 쥐가 지렛대를 누르는 행동을 하게 되면 먹이이라는 보상을 받게 된다.

​	쥐는 지렛대를 눌렀을때 왜 먹이가 나오는건지 이해한것은 아니지만 지렛대를 밟을 때 마다 먹이가 나온다는것을 여러 시행착오(Trial and Error)를 통해 	알게 되고 강화가 된다.

​	따라서 이해를 못하더라도 행동과 행동의 결과를 보상으로 연결할 수 있다.

<br/>

<br/>

<br/>

# 강화학습 구성 요소

<br/>

<img src="https://blog.kakaocdn.net/dn/eHG6CH/btqIql1mYv1/vJubkvkgmsAZT4gvAwbbQK/tfile.dat" alt="img" style="zoom:67%;" />

## **에이전트(agent)**

- **강화학습을 통해 스스로 학습하는 컴퓨터 자신**
- *ex) 스카너의 실험 : 쥐*
- *ex) 실제 세상 : 자기자신*

<br/>

## **상태(state)**

- **agent의 상태(정보)**
- "agent 자신의 상황에 대한 관찰"
- *ex) 스카너의 실험 : 쥐의 건강 상태(배고픔, 배부름 등...)*
- *ex) 실제 세상 : 나 자신의 상태(나의 기분, 나의 체력, 나의 위치, 나의 속도 등...)*

<br/>

## **환경(environment)**

- **agent를 제외한 모든것들**
- *ex) 스카너의 실험 : 쥐를 제외한 모든것들(상자, 지렛대, 먹이 등...)*
- *ex) 실제 세상 : 나를 제외한 모든것들(사람들, 가지고 있는 물건,  집, 지구 등...)*

<br/>

## **행동(action)**

- **agent가 하는 행동 종류(action set)**
- 강화학습에서는 상태(state)를 판단하여 행동을 결정
- *ex) 스카너의 실험 : 쥐의 행동(지렛대 누르기, 걷기, 자기)*
- *ex) 실제 세상 : 내가 하는 행동(앞으로 걸어가기, 옆사람에게 말을 걸기 등...)*

<br/>

## **보상(reward)**

- **목표(goal)를 만족시켰을때의 보상**
- 강화학습에서는 환경이 agent에게 보상을 줌
- 보상을 통해 agent의 행동들을 피드백할 수 있음
- *ex) 스카너의 실험 : 먹이*
- *ex) 실제 세상 : 내가 환경으로 부터 보상을 받음(한달 일을하고 월급을 받음, 옆사람에게 말을 걸어 호감을 얻음 등...)*

<br/>

## 정책(policy)

- **모든 상태에 대해 agent가 어떤 행동을 해야 하는지 정해놓은 규칙**
- agent가 학습한 내용(어떠한 행동을 했을떄 보상이 더 많았다 라든지)에 대해 피드백을 적용한 결론
- *ex) 스카너의 실험 : 쥐가 먹이를 먹으려고 많은 시행착오를 통해 학습하여 지렛대를 누르는 행동을 선택할 확률을 높이는 스스로의 규칙*
- *ex) 실제 세상 : 내가 6시경 차가 차가 안막히는 경로를 많은 시행착오를 통해 학습해서 그 경로를 선택하는 행동의 확률을 높이는 일종의 규칙*

<br/>

<br/>

<br/>

# 강화학습이 하고자 하는것은?

<br/>

에이전트(agent)가 여러 행동(action)을 통해 환경(environment)를 순차적으로 탐색하면서 얻는 보상(reward)들의 합을 최대화 하는 "최적 행동양식", 또는 "최적 정책"을 학습히는 것이다.

<br/>

<br/>

<br/>

# 강화학습을 풀기위해서는?

<br/>

강화학습을 풀기위해서는 결국 컴퓨터 프로그래밍으로 알고리즘을 짜야 한다.

그런데 프로그램이 문제를 풀기위해서는 그 문제가 수학적으로 정의가 되어야 한다.

따라서 우리는 강화학습과 같은 순차적 행동 결정 문제에 대해서 MDP(Markov Decision Process)로 정의해서 알고리즘을 만들 수 있다.

다음 포스트에는 MDP 에 대해서 설명을 할 예정이다.

<br/>

<br/>

<br/>

------

*제가 올린 글에서 잘못된 부분이 있으면 제 메일로 연락주세요!*

*Reference : 파이썬과 케라스로 배우는 강화학습*

<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="크리에이티브 커먼즈 라이선스" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png" /></a><br /><span xmlns:cc="http://creativecommons.org/ns#" property="cc:attributionName">이승수</span>의 저작물인 이 저작물은(는) <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">크리에이티브 커먼즈 저작자표시-비영리-동일조건변경허락 4.0 국제 라이선스</a>에 따라 이용할 수 있습니다.

<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="크리에이티브 커먼즈 라이선스" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png" /></a><br /><span xmlns:cc="http://creativecommons.org/ns#" property="cc:attributionName">이승수</span>의 저작물인 이 저작물은(는) <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">크리에이티브 커먼즈 저작자표시-비영리-동일조건변경허락 4.0 국제 라이선스</a>에 따라 이용할 수 있습니다.